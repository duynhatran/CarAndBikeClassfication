{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161754 1000 41006\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "train_raw = []\n",
    "test_raw = []\n",
    "val_raw = []\n",
    "with open('../mmsys_anns/train_data.json') as f:\n",
    "    for line in f:\n",
    "        train_raw.append(json.loads(line))\n",
    "with open('../mmsys_anns/public_test_mmsys_final.json') as f:\n",
    "    for line in f:\n",
    "        test_raw.append(json.loads(line))\n",
    "with open('../mmsys_anns/val_data.json') as f:\n",
    "    for line in f:\n",
    "        val_raw.append(json.loads(line))\n",
    "print(len(train_raw), len(test_raw), len(val_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating in context pairs: 100%|██████████| 161754/161754 [00:00<00:00, 357952.03it/s]\n",
      "Total length of train_dataset 232290\n",
      "Counter 56381\n"
     ]
    }
   ],
   "source": [
    "# Path: notebooks\\prepare_dataset.ipynb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "seed = 42\n",
    "train_caption_pairs = []\n",
    "counter=0\n",
    "for idx,item in tqdm(enumerate(train_raw), total=len(train_raw), desc='Generating in context pairs'):\n",
    "    temp_dict = {}\n",
    "    if len(item['articles']) == 1:\n",
    "        counter += 1\n",
    "        continue\n",
    "    temp_dict['img_path'] = item['img_local_path']\n",
    "    num_articles = len(item['articles'])\n",
    "    for i in range(num_articles):\n",
    "        for j in range(num_articles):\n",
    "            if i == j:\n",
    "                continue\n",
    "            temp_dict['caption_1']=item['articles'][i]['caption']\n",
    "            temp_dict['caption_2']=item['articles'][j]['caption']\n",
    "            if temp_dict['caption_1'] == temp_dict['caption_2']:\n",
    "                continue\n",
    "            train_caption_pairs.append(temp_dict.copy())\n",
    "            break\n",
    "print(\"Total length of train_dataset\",len(train_caption_pairs),file=sys.stderr)\n",
    "print(\"Counter\",counter,file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating in context pairs for validation set: 100%|██████████| 41006/41006 [00:00<00:00, 611362.76it/s]\n",
      "Total length of val_dataset 26024\n",
      "Counter 71363\n"
     ]
    }
   ],
   "source": [
    "val_caption_pairs = []\n",
    "# for idx,item in tqdm(enumerate(val_raw), total=len(val_raw), desc='Generating out of context pairs for validation set'):\n",
    "#     temp_dict = {}\n",
    "#     temp_dict['img_path'] = item['img_local_path']\n",
    "#     temp_dict['caption_1'] = item['articles'][0]['caption']\n",
    "#     rand_idx = np.random.randint(0, len(val_raw)-1)\n",
    "#     while rand_idx == idx:\n",
    "#         rand_idx = np.random.randint(0, len(val_raw)-1)\n",
    "#     temp_dict['caption_2'] = val_raw[rand_idx]['articles'][0]['caption']\n",
    "#     temp_dict['label'] = 1\n",
    "#     val_caption_pairs.append(temp_dict)\n",
    "# counter = 0\n",
    "for idx,item in tqdm(enumerate(val_raw), total=len(val_raw), desc='Generating in context pairs for validation set'):\n",
    "    temp_dict = {}\n",
    "    if len(item['articles']) == 1:\n",
    "        counter += 1\n",
    "        continue\n",
    "    temp_dict['img_path'] = item['img_local_path']\n",
    "    temp_dict['caption_1'] = item['articles'][0]['caption']\n",
    "    temp_dict['caption_2'] = item['articles'][1]['caption']\n",
    "    temp_dict['label'] = 0\n",
    "    val_caption_pairs.append(temp_dict)\n",
    "print(\"Total length of val_dataset\",len(val_caption_pairs),file=sys.stderr)\n",
    "print(\"Counter\",counter,file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_val_v2_2.json\",'w',encoding='utf8') as f:\n",
    "    train_dict = {'train':train_caption_pairs, 'val':val_caption_pairs}\n",
    "    json.dump(train_dict, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/1.jpg\n",
      "train/2.jpg\n",
      "train/0.jpg\n",
      "train/1.jpg\n",
      "train/2.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_raw[i]['img_local_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161752\n"
     ]
    }
   ],
   "source": [
    "temp_set = set()\n",
    "for i in range(len(train_raw)):\n",
    "    temp_set.add(train_raw[i]['img_local_path'])\n",
    "print(len(temp_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path': 'train/1.jpg',\n",
       " 'caption_1': 'The technical infrastructure of WhatsApp, Instagram and Facebook Messenger will be unified.',\n",
       " 'caption_2': 'This photo taken March 22, 2018, shows apps for WhatsApp, Facebook, Instagram and other social networks on a smartphone.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_caption_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheapfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
